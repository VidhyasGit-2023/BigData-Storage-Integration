-- Start Spark

spark-shell --master yarn

import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.feature.{RegexTokenizer, StopWordsRemover, CountVectorizer}
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.param.ParamMap
import org.apache.spark.ml.tuning.{CrossValidator, CrossValidatorModel, ParamGridBuilder}

val newsArticleSchema = new StructType(Array(
  StructField("title", StringType, true),
  StructField("author", StringType, true),
  StructField("publishedAt", StringType, true),
  StructField("description", StringType, true)
))

val newsStream = spark.read
  .format("json")
  .schema(newsArticleSchema)
  .load("hdfs://bigdatavidhya-m:8051/home/bigdatabigdata107/news/data/kafka_messages.json")

val selectedData = newsStream.select("description")

val labeledData = selectedData.withColumn("label",
  when(lower(col("description")).contains("plus") || lower(col("description")).contains("good"), 1.0D)
    .otherwise(0.0D)
)

val Array(trainingData, testData) = labeledData.randomSplit(Array(0.8, 0.2))

val tokenizer = new RegexTokenizer()
  .setInputCol("description")
  .setOutputCol("words")
  .setPattern("\\W")

val remover = new StopWordsRemover()
  .setInputCol("words")
  .setOutputCol("filtered")

val vectorizer = new CountVectorizer()
  .setInputCol("filtered")
  .setOutputCol("features")

val lr = new LogisticRegression()
  .setMaxIter(10)
  .setRegParam(0.2)
  .setElasticNetParam(0.0)

val pipeline = new Pipeline().setStages(Array(tokenizer, remover, vectorizer, lr))

val model = pipeline.fit(trainingData)

val predictions = model.transform(testData)

predictions.select("description", "label", "prediction").show()

val evaluator = new MulticlassClassificationEvaluator()
  .setLabelCol("label")
  .setPredictionCol("prediction")
  .setMetricName("accuracy")

val accuracy = evaluator.evaluate(predictions)
println(s"Accuracy on test data: $accuracy")