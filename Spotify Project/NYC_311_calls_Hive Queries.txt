Midterm project - PROG 8450 - Assignment 1 - Analyzing New York City 311 Calls Using Apache Hive - Vidhya Venugopal - 8902970
-------------------------------------------------------------------------------------------------------------------------------

1) Downloaded the nyc_311 call dataset from the below location

wget https://www.dropbox.com/s/nmz1zd2bw2n5ora/nyc_311_sample.csv

2) Loaded the dataset into HDFS in the following location as mentioned

hadoop fs -mkdir /user/VidhyaV/311_calls

hadoop fs -copyFromLocal nyc_311_sample.csv /user/VidhyaV/311_calls/

3) Created a database and a hive table with same fields as in dataset

hive

CREATE DATABASE 311_calls;
USE 311_calls;

-- Creating a table skeleton, there is no data in this table yet

hive> CREATE TABLE IF NOT EXISTS nycDataVidhya (
uniquekey INT,
createddate STRING,
closeddate STRING,
agency STRING,
agencyname STRING,
complainttype STRING,
descriptor STRING,
locationtype STRING,
incidentzip INT,
incidentaddress STRING,
streetname STRING,
crossstreet1 STRING,
crossstreet2 STRING,
intersectionstreet1 STRING,
intersectionstreet2 STRING,
addresstype STRING,
city STRING,
landmark STRING,
facilitytype STRING,
status STRING,
duedate STRING,
resolutiondescription STRING,
resolutionactionupdateddate STRING,
communityboard STRING,
bbl INT,
borough STRING,
xcoordinate INT,
ycoordinate INT,
opendatachanneltype STRING,
parkfacilityname STRING,
parkborough STRING,
vehicletype STRING,
taxicompanyborough STRING,
taxipickuplocation STRING,
bridgehighwayname STRING,
bridgehighwaydirection STRING,
roadramp STRING,
bridgehighwaysegment STRING,
latitude STRING,
longitude STRING,
location STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
TBLPROPERTIES ('creator'='Big Data class', 'created_on' = '2023-11-23', 'description'='This table NYC 311 call data.',
'skip.header.line.count'='1');

4) Loaded the data from the dataset corresponding location to the newly created hive table

### *** METHOD 1 *** LOAD DATASAET USING LOAD COMMAND ###

-- this command MOVES the data from the hive folder into the location folder specified in the Metadata

hive> LOAD DATA INPATH '/user/VidhyaV/311_calls/nyc_311_sample.csv' INTO TABLE nycDataVidhya;

-- Since the file has been be moved, the following directory will be empty

hive> !hadoop fs -ls /user/VidhyaV/311_calls/;

--check out the location of the data for this table

hive> DESCRIBE FORMATTED nycDataVidhya;

-- display the contents of the folder (should see the nyc 311 call Data)

hive> !hadoop fs -ls /user/hive/warehouse/311_calls.db/nycdatavidhya;

-- very powerful, we now have our data in table format and can use familiar SQL queries

hive> SELECT * FROM nycDataVidhya LIMIT 100;

5) Analyze the data using Hive for the following scenario's

a) -- Top complaints: The dataset can provide information on the most common complaints and service requests made to the 311 call center.

SELECT complainttype, COUNT(*) AS total_complaints
FROM nycDataVidhya
GROUP BY complainttype
ORDER BY total_complaints DESC
LIMIT 10;

b) -- Geographic distribution: The dataset can be used to analyze the geographic distribution of complaints and requests, allowing the city to identify areas with higher levels of need.

SELECT borough, COUNT(*) AS total_complaints_by_area
FROM nycDataVidhya
GROUP BY borough
ORDER BY total_complaints_by_area DESC
LIMIT 5;

c) -- Response times: The dataset contains information on the response times for different types of complaints and requests.

SELECT 
    complainttype,
    COUNT(DATEDIFF(FROM_UNIXTIME(UNIX_TIMESTAMP(closeddate, 'MM/dd/yyyy hh:mm:ss aa')), FROM_UNIXTIME(UNIX_TIMESTAMP(createddate, 'MM/dd/yyyy hh:mm:ss aa')))) AS response_time_days
FROM nycDataVidhya
    WHERE closeddate IS NOT NULL
    GROUP BY complainttype
    ORDER BY response_time_days DESC
LIMIT 10;